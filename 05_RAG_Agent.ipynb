{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is owned by Antonio Rossi, a renowned chef with over 20 years of experience in the culinary industry. He started Bella Vista to bring authentic Italian flavors to the community.\",\n",
    "        metadata={\"source\": \"owner.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a range of dishes with prices that cater to various budgets. Appetizers start at $8, main courses range from $15 to $35, and desserts are priced between $6 and $12.\",\n",
    "        metadata={\"source\": \"dishes.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista is open from Monday to Sunday. Weekday hours are 11:00 AM to 10:00 PM, while weekend hours are extended from 11:00 AM to 11:00 PM.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Bella Vista offers a variety of menus including a lunch menu, dinner menu, and a special weekend brunch menu. The lunch menu features light Italian fare, the dinner menu offers a more extensive selection of traditional and contemporary dishes, and the brunch menu includes both classic breakfast items and Italian specialties.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function, persist_directory=\"./chroma_db_2\")\n",
    "# retriever = db.as_retriever()\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NisimHurst\\NDS\\rh\\capacitaciones\\LangGraph\\LangGraph-Udemy-Course\\venv\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: list[BaseMessage]\n",
    "    documents: list[Document]\n",
    "    on_topic: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class GradeQuestion(BaseModel):\n",
    "    \"\"\"Boolean value to check whether a question is releated to the restaurant Bella Vista\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"Question is about restaurant? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def question_classifier(state: AgentState):\n",
    "    question = state[\"messages\"][-1].content\n",
    "\n",
    "    system = \"\"\"You are a classifier that determines whether a user's question is about one of the following topics:\n",
    "\n",
    "    1. Information about the owner of Bella Vista, which is Antonio Rossi.\n",
    "    2. Prices of dishes at Bella Vista (restaurant).\n",
    "    3. Opening hours of Bella Vista (restaurant).\n",
    "\n",
    "    If the question IS about any of these topics, respond with 'Yes'. Otherwise, respond with 'No'. Remember, ONLY YES or NO, nothing else in the reponse!\n",
    "    \"\"\"\n",
    "\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"User question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({\"question\": question})\n",
    "    print(\"RESULT\", result)\n",
    "    state[\"on_topic\"] = result.score\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_topic_router(state):\n",
    "    on_topic = state[\"on_topic\"]\n",
    "    if on_topic.lower() == \"yes\":\n",
    "        return \"on_topic\"\n",
    "    return \"off_topic\"\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    documents = retriever.invoke(question)\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_answer(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    state[\"messages\"].append(generation)\n",
    "    return state\n",
    "\n",
    "\n",
    "def off_topic_response(state: AgentState):\n",
    "    state[\"messages\"].append(AIMessage(content=\"I cant respond to that!\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"topic_decision\", question_classifier)\n",
    "workflow.add_node(\"off_topic_response\", off_topic_response)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"topic_decision\",\n",
    "    on_topic_router,\n",
    "    {\n",
    "        \"on_topic\": \"retrieve\",\n",
    "        \"off_topic\": \"off_topic_response\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"generate_answer\")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"off_topic_response\", END)\n",
    "\n",
    "workflow.set_entry_point(\"topic_decision\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tagent(agent)\n",
      "\ttools(tools)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> agent;\n",
      "\ttools --> agent;\n",
      "\tagent -.-> tools;\n",
      "\tagent -.-> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "import re\n",
    "from typing import Optional\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from langchain_core.runnables import graph_mermaid\n",
    "\n",
    "def render_mermaid_using_api(\n",
    "    mermaid_syntax: str,\n",
    "    output_file_path: Optional[str] = None,\n",
    "    background_color: Optional[str] = \"white\",\n",
    "    file_type: Optional[Literal[\"jpeg\", \"png\", \"webp\"]] = \"png\",\n",
    ") -> bytes:\n",
    "    \"\"\"Renders Mermaid graph using the Mermaid.INK API.\"\"\"\n",
    "    try:\n",
    "        import requests  # type: ignore[import]\n",
    "    except ImportError as e:\n",
    "        msg = (\n",
    "            \"Install the `requests` module to use the Mermaid.INK API: \"\n",
    "            \"`pip install requests`.\"\n",
    "        )\n",
    "        raise ImportError(msg) from e\n",
    "\n",
    "    # Use Mermaid API to render the image\n",
    "    print(mermaid_syntax)\n",
    "    mermaid_syntax_encoded = base64.b64encode(mermaid_syntax.encode(\"utf8\")).decode(\n",
    "        \"ascii\"\n",
    "    )\n",
    "\n",
    "    # Check if the background color is a hexadecimal color code using regex\n",
    "    if background_color is not None:\n",
    "        hex_color_pattern = re.compile(r\"^#(?:[0-9a-fA-F]{3}){1,2}$\")\n",
    "        if not hex_color_pattern.match(background_color):\n",
    "            background_color = f\"!{background_color}\"\n",
    "\n",
    "    image_url = (\n",
    "        f\"http://localhost:3000/img/{mermaid_syntax_encoded}\"\n",
    "        # f\"https://mermaid.ink/img/{mermaid_syntax_encoded}\"\n",
    "        f\"?type={file_type}&bgColor={background_color}\"\n",
    "    )\n",
    "    response = requests.get(image_url, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        img_bytes = response.content\n",
    "        if output_file_path is not None:\n",
    "            with open(output_file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "        return img_bytes\n",
    "    else:\n",
    "        msg = (\n",
    "            f\"Failed to render the graph using the Mermaid.INK API. \"\n",
    "            f\"Status code: {response.status_code}.\"\n",
    "        )\n",
    "        raise ValueError(msg)\n",
    "\n",
    "graph_mermaid._render_mermaid_using_api = render_mermaid_using_api\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "            output_file_path=\"graph.png\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT score='When does the bella vista restaurant open?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='When does the bella vista restaurant open?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I cant respond to that!', additional_kwargs={}, response_metadata={})],\n",
       " 'on_topic': 'When does the bella vista restaurant open?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=\"When does the bella vista restaurant open?\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT score='No'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is articial intelligence?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I cant respond to that!', additional_kwargs={}, response_metadata={})],\n",
       " 'on_topic': 'No'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"What is articial intelligence?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_tool\",\n",
    "    \"Information related to Pricing, Opening hours of the owner of the restaurant Bella Vista\",\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def off_topic():\n",
    "    \"\"\"Catch all Questions NOT related to Pricing, Opening hours of the owner of the restaurant Bella Vista\"\"\"\n",
    "    return \"Forbidden - do not respond to the user\"\n",
    "\n",
    "\n",
    "tools = [retriever_tool, off_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI()\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\"messages\": [HumanMessage(content=\"How will the weather be tommorrow?\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=\"When does the bella vista restaurant open?\")]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
